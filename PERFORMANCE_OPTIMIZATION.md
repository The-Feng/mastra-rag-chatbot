# 性能優化說明

## 📊 已實施的優化

### 1. 批量處理優化

- ✅ **向量嵌入批次大小**：1000 個片段/批次（OpenAI API 限制）
- ✅ **數據庫插入批次大小**：從 200 增加到 500 條/批次
- ✅ **減少數據庫往返次數**：批量插入減少網絡開銷

### 2. 進度提示

- ✅ 添加詳細的進度日誌
- ✅ 顯示每個步驟的耗時
- ✅ 讓用戶了解當前處理進度

### 3. 查詢優化

- ✅ 使用索引優化向量搜索
- ✅ 減少總結檢索片段數量（從 10 個減少到 5 個）
- ✅ 使用時間戳精確匹配，利用索引

## ⚡ 性能瓶頸分析

### 主要瓶頸

1. **OpenAI API 調用**（無法避免）
   - 向量嵌入生成：網絡請求，取決於 OpenAI API 響應速度
   - LLM 生成總結：網絡請求，取決於模型響應速度
   - **這是最大的性能瓶頸**

2. **數據庫操作**
   - 向量插入：已優化為批量插入
   - 向量搜索：已使用索引優化

3. **文檔處理**
   - 文件解析：PDF/Word 解析速度
   - 文本分塊：內存操作，速度較快

## 🚀 進一步優化建議

### 1. 異步處理（推薦）

將總結生成改為異步，先返回導入結果：

```typescript
// 立即返回導入結果
return {
  count: ingestResult.count,
  message: `成功导入 ${ingestResult.count} 个文档片段`,
};

// 後台生成總結（可選）
summarizeDocument().then(summary => {
  // 通過 WebSocket 或輪詢返回總結
});
```

### 2. 使用更快的嵌入模型

考慮使用更快的模型（如果可用）：

```typescript
// 當前：text-embedding-3-small（1536 維）
// 可選：更快的模型（如果 OpenAI 提供）
model: openai.embedding("text-embedding-3-small")
```

### 3. 緩存機制

對於重複查詢，可以添加緩存：

```typescript
// 緩存常見查詢的向量嵌入
const cache = new Map<string, number[]>();
```

### 4. 並行處理

對於多個文檔，可以並行處理：

```typescript
// 並行處理多個文檔（如果有多個文件）
await Promise.all(files.map(file => ingestFile(...)));
```

### 5. 減少分塊大小

如果文檔較小，可以減少分塊數量：

```typescript
// 當前：maxSize: 512, overlap: 50
// 可選：增加 maxSize 減少分塊數量
const chunks = await doc.chunk({ 
  strategy: "recursive", 
  maxSize: 1024,  // 增加分塊大小
  overlap: 100 
});
```

## 📈 性能指標

### 典型處理時間（11 個片段）

- **文檔分塊**：< 100ms
- **向量嵌入生成**：~2-5 秒（取決於 OpenAI API）
- **數據庫插入**：~200-500ms
- **總結生成**：~3-8 秒（取決於 OpenAI API）

**總計**：約 5-15 秒（主要取決於 OpenAI API 響應速度）

### 優化後預期

- **向量嵌入生成**：已優化批次大小
- **數據庫插入**：已優化批次大小（減少 60% 的插入次數）
- **進度提示**：用戶體驗改善

## 💡 使用建議

### 對於小文檔（< 1000 字）

- 處理速度較快（< 5 秒）
- 可以同步等待結果

### 對於大文檔（> 10000 字）

- 考慮異步處理
- 先返回導入結果
- 後台生成總結

### 對於批量上傳

- 考慮並行處理
- 或使用隊列系統

## 🔧 配置調整

### 調整批次大小

在 `src/mastra/rag.ts` 中：

```typescript
// 向量嵌入批次大小（最大 2048）
const batchSize = 1000;

// 數據庫插入批次大小（可根據數據庫性能調整）
const insertBatchSize = 500;
```

### 調整分塊參數

```typescript
// 增加分塊大小，減少分塊數量
const chunks = await doc.chunk({ 
  strategy: "recursive", 
  maxSize: 1024,  // 從 512 增加到 1024
  overlap: 100    // 從 50 增加到 100
});
```

## 📝 總結

- ✅ **已優化**：數據庫插入批次大小、進度提示
- ⚠️ **主要瓶頸**：OpenAI API 調用（網絡請求，無法避免）
- 💡 **建議**：對於大文檔，考慮異步處理總結生成

性能優化是一個持續的過程，根據實際使用情況調整參數。


