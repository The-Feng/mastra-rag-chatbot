import { MDocument } from "@mastra/rag";
import { embedMany, streamText } from "ai";
import { openai } from "@ai-sdk/openai";
import { getPool } from "./db.js";
import { ensureVectorDB } from "./db.js";
import mammoth from "mammoth";
import { writeFile, unlink, access } from "fs/promises";
import { join } from "path";
import { tmpdir } from "os";
import { exec } from "child_process";
import { promisify } from "util";

const execAsync = promisify(exec);

// Import document to vector database
export async function ingestText(text: string, source = "upload") {
  await ensureVectorDB();
  const doc = MDocument.fromText(text);
  const chunks = await doc.chunk({ strategy: "recursive", maxSize: 512, overlap: 50 });

  console.log(`ğŸ“¦ æ–‡æ¡£å·²åˆ†å—: ${chunks.length} ä¸ªç‰‡æ®µ`);

  const pool = getPool();

  // ä¼˜åŒ–ï¼šå¢åŠ æ‰¹æ¬¡å¤§å°ä»¥æé«˜æ•ˆç‡ï¼ˆOpenAI API æ”¯æŒæœ€å¤š 2048 ä¸ªæ–‡æœ¬ï¼‰
  const batchSize = 1000;
  let totalProcessed = 0;
  const uploadTimestamp = Date.now();

  for (let i = 0; i < chunks.length; i += batchSize) {
    const batch = chunks.slice(i, i + batchSize);
    const batchTexts = batch.map(c => c.text);

    console.log(`ğŸ”„ æ­£åœ¨ç”Ÿæˆå‘é‡åµŒå…¥ (${i + 1}-${Math.min(i + batchSize, chunks.length)}/${chunks.length})...`);
    const embedStartTime = Date.now();
    
    const { embeddings } = await embedMany({
      values: batchTexts,
      model: openai.embedding("text-embedding-3-small"),
    });

    const embedTime = Date.now() - embedStartTime;
    console.log(`âœ… å‘é‡åµŒå…¥å®Œæˆ (${batch.length} ä¸ª, è€—æ—¶ ${embedTime}ms)`);

    // ä¼˜åŒ–ï¼šå¢åŠ æ’å…¥æ‰¹æ¬¡å¤§å°ï¼Œå‡å°‘æ•°æ®åº“å¾€è¿”æ¬¡æ•°
    const insertBatchSize = 500; // ä» 200 å¢åŠ åˆ° 500
    console.log(`ğŸ’¾ æ­£åœ¨æ’å…¥æ•°æ®åº“...`);
    const insertStartTime = Date.now();
    
    for (let batchStart = 0; batchStart < batch.length; batchStart += insertBatchSize) {
      const insertBatch = batch.slice(batchStart, batchStart + insertBatchSize);
      const values: any[] = [];
      const placeholders: string[] = [];
      let paramIndex = 1;
      
      for (let j = 0; j < insertBatch.length; j++) {
        const chunkIndex = i + batchStart + j;
        // ä½¿ç”¨æ—¶é—´æˆ³ + æ–‡ä»¶å + chunkIndex ç¡®ä¿å”¯ä¸€æ€§
        const id = `${uploadTimestamp}-${source}-${chunkIndex}`;
        const vector = `[${embeddings[batchStart + j].join(",")}]`;
        const metadata = JSON.stringify({ source, uploadedAt: uploadTimestamp });
        
        placeholders.push(`($${paramIndex}, $${paramIndex + 1}, $${paramIndex + 2}, $${paramIndex + 3}, CURRENT_TIMESTAMP)`);
        values.push(id, insertBatch[j].text, vector, metadata);
        paramIndex += 4;
      }
      
      // æ‰¹é‡æ’å…¥ï¼Œæé«˜æ€§èƒ½ï¼ˆä½¿ç”¨è¿æ¥æ± ï¼‰
      await pool.query(
        `INSERT INTO docs(id, text, vector, metadata, created_at) VALUES ${placeholders.join(", ")}
         ON CONFLICT (id) DO UPDATE SET text = EXCLUDED.text, vector = EXCLUDED.vector, metadata = EXCLUDED.metadata, created_at = CURRENT_TIMESTAMP`,
        values
      );
    }

    const insertTime = Date.now() - insertStartTime;
    console.log(`âœ… æ•°æ®åº“æ’å…¥å®Œæˆ (${batch.length} æ¡, è€—æ—¶ ${insertTime}ms)`);

    totalProcessed += batch.length;
  }

  console.log(`ğŸ‰ æ–‡æ¡£å¯¼å…¥å®Œæˆ: å…± ${totalProcessed} ä¸ªç‰‡æ®µ`);
  return { count: totalProcessed };
}

// å¤„ç†æ–‡ä»¶ä¸Šä¼ ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
export async function ingestFile(buffer: Buffer, fileName: string, mimeType: string) {
  let text = "";

  // æ ¹æ®æ–‡ä»¶ç±»å‹æå–æ–‡æœ¬
  if (mimeType.includes("pdf") || fileName.endsWith(".pdf")) {
    try {
      // ä½¿ç”¨å‹•æ…‹å°å…¥ pdf-parseï¼ˆES modules å…¼å®¹ï¼‰
      const pdfParse = await import("pdf-parse");
      const pdfParseDefault = pdfParse.default || pdfParse;
      
      // pdf-parse è¿”å›ä¸€å€‹ Promiseï¼Œç›´æ¥å‚³å…¥ buffer
      const pdfData = await pdfParseDefault(buffer);
      text = pdfData.text || "";
      
      if (!text || text.trim().length === 0) {
        throw new Error("No text content extracted from PDF file");
      }
      
      console.log(`PDF parsing successful, extracted ${text.length} characters`);
    } catch (error) {
      console.error("PDF parsing error:", error);
      const errorMessage = error instanceof Error ? error.message : "Unknown error";
      console.error("PDF parsing detailed error:", {
        message: errorMessage,
        stack: error instanceof Error ? error.stack : undefined,
        bufferLength: buffer.length,
        errorType: error instanceof Error ? error.constructor.name : typeof error
      });
      throw new Error(`PDF parsing failed: ${errorMessage}`);
    }
  } else if (
    mimeType.includes("wordprocessingml") || 
    fileName.endsWith(".docx")
  ) {
    // mammoth åªæ”¯æŒ .docx æ ¼å¼ï¼ˆåŸºäº ZIPï¼‰ï¼Œä¸æ”¯æŒæ—§çš„ .doc æ ¼å¼
    try {
      const result = await mammoth.extractRawText({ buffer });
      text = result.value;
      
      if (!text || text.trim().length === 0) {
        throw new Error("No text content extracted from Word document");
      }
    } catch (error) {
      console.error("Word parsing error:", error);
      const errorMsg = error instanceof Error ? error.message : "Unknown error";
      if (errorMsg.includes("zip file") || errorMsg.includes("central directory")) {
        throw new Error("Word document format error. Please ensure you upload .docx format (Word 2007+), old .doc format is not supported.");
      }
      throw new Error(`Word document parsing failed: ${errorMsg}`);
    }
  } else if (
    mimeType.includes("msword") || 
    fileName.endsWith(".doc")
  ) {
    // ä½¿ç”¨ antiword ç›´æ¥å¤„ç†æ—§çš„ .doc æ ¼å¼ï¼ˆWord 97-2003ï¼‰
    try {
      console.log("å¼€å§‹å¤„ç† .doc æ–‡ä»¶...");
      
      // å°† buffer å†™å…¥ä¸´æ—¶æ–‡ä»¶
      const tempFilePath = join(tmpdir(), `doc-${Date.now()}-${Math.random().toString(36).substring(7)}.doc`);
      await writeFile(tempFilePath, buffer);
      console.log("ä¸´æ—¶æ–‡ä»¶å·²å†™å…¥:", tempFilePath);
      
      try {
        // å°è¯•å¤šä¸ªå¯èƒ½çš„ antiword è·¯å¾„
        const possiblePaths = [
          "/opt/homebrew/bin/antiword",  // macOS Homebrew (Apple Silicon)
          "/usr/local/bin/antiword",     // macOS Homebrew (Intel) æˆ– Linux
          "/usr/bin/antiword",           // Linux ç³»ç»Ÿè·¯å¾„
          "antiword"                     // å¦‚æœåœ¨ PATH ä¸­
        ];
        
        let antiwordPath = "";
        
        // å°è¯•æ‰¾åˆ°å¯ç”¨çš„ antiword
        for (const path of possiblePaths) {
          try {
            if (path === "antiword") {
              // ç›´æ¥ä½¿ç”¨å‘½ä»¤åç§°ï¼Œä¾èµ– PATH
              await execAsync(`which ${path}`);
              antiwordPath = path;
              break;
            } else {
              // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
              try {
                await access(path);
                antiwordPath = path;
                break;
              } catch {
                continue;
              }
            }
          } catch {
            continue;
          }
        }
        
        if (!antiwordPath) {
          throw new Error(`Cannot find antiword. Please ensure it is installed:\nmacOS: brew install antiword\nLinux: sudo apt-get install antiword or sudo yum install antiword`);
        }
        
        console.log("Using antiword path:", antiwordPath);
        
        // è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿å¯ä»¥æ‰¾åˆ° antiword
        const env = {
          ...process.env,
          PATH: process.env.PATH || "",
        };
        
        // å¦‚æœä½¿ç”¨å®Œæ•´è·¯å¾‘ï¼Œç¢ºä¿ PATH åŒ…å«å…¶ç›®éŒ„
        if (antiwordPath !== "antiword") {
          const antiwordDir = join(antiwordPath, "..");
          env.PATH = `${antiwordDir}:${env.PATH}`;
        }
        
        // æ‰§è¡Œ antiword å‘½ä»¤æå–æ–‡æœ¬
        console.log("å¼€å§‹æ‰§è¡Œ antiword...");
        const { stdout, stderr } = await execAsync(
          `"${antiwordPath}" "${tempFilePath}"`,
          { 
            env,
            maxBuffer: 10 * 1024 * 1024, // 10MB ç¼“å†²åŒº
            timeout: 30000 // 30 ç§’è¶…æ—¶
          }
        );
        
        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try {
          await unlink(tempFilePath);
          console.log("ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†");
        } catch (unlinkError) {
          console.error("æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥:", unlinkError);
        }
        
        if (stderr && !stderr.includes("antiword")) {
          console.warn("antiword è­¦å‘Š:", stderr);
        }
        
        text = stdout || "";
        
        if (!text || text.trim().length === 0) {
          throw new Error("No text content extracted from .doc file");
        }
        
        console.log(`Successfully extracted text, length: ${text.length} characters`);
      } catch (execError: any) {
        // Clean up temporary file
        try {
          await unlink(tempFilePath);
        } catch {
          // Ignore cleanup errors
        }
        
        const errorMsg = execError?.message || "Unknown error";
        if (errorMsg.includes("ENOENT") || errorMsg.includes("not found") || errorMsg.includes("ç„¡æ³•æ‰¾åˆ°")) {
          throw new Error(`Cannot find antiword command. Please install:\nmacOS: brew install antiword\nLinux (Debian/Ubuntu): sudo apt-get install antiword\nLinux (CentOS/RHEL): sudo yum install antiword`);
        }
        if (errorMsg.includes("timeout")) {
          throw new Error(`.doc file processing timeout. File may be too large or corrupted.`);
        }
        throw new Error(`.doc file parsing failed: ${errorMsg}`);
      }
    } catch (error) {
      console.error("DOC parsing error:", error);
      const errorMsg = error instanceof Error ? error.message : "Unknown error";
      throw new Error(`.doc file parsing failed: ${errorMsg}`);
    }
  } else {
    // çº¯æ–‡æœ¬æ–‡ä»¶
    text = buffer.toString("utf-8");
  }

  if (!text || text.trim().length === 0) {
    throw new Error("Unable to extract text content from file. File may be empty or format is not supported");
  }

  return await ingestText(text, fileName);
}

// RAG æ£€ç´¢ + ç”Ÿæˆ
export async function askRag(query: string) {
  const { embeddings: [queryEmbedding] } = await embedMany({
    values: [query],
    model: openai.embedding("text-embedding-3-small"),
  });

  const pool = getPool();

  // æ£€ç´¢ç­–ç•¥ï¼šåªæ£€ç´¢æœ€æ–°ä¸Šä¼ çš„æ–‡æ¡£
  // ä½¿ç”¨ç´¢å¼•ä¼˜åŒ–çš„æŸ¥è¯¢ï¼Œç›´æ¥æ£€ç´¢æœ€æ–°æ–‡æ¡£
  const queryVector = `[${queryEmbedding.join(",")}]`;
  
  // ä¼˜åŒ–ï¼šç›´æ¥æŸ¥è¯¢æœ€æ–°ä¸Šä¼ çš„æ–‡æ¡£ï¼ˆä½¿ç”¨ç´¢å¼•ï¼‰
  const latestDocResult = await pool.query(
    `SELECT metadata->>'uploadedAt' as latest_timestamp
     FROM docs
     WHERE metadata->>'uploadedAt' IS NOT NULL
     ORDER BY (metadata->>'uploadedAt')::bigint DESC
     LIMIT 1`
  );
  
  const latestTimestamp = latestDocResult.rows[0]?.latest_timestamp;
  
  let rows;
  
  if (latestTimestamp) {
    // åªæ£€ç´¢æœ€æ–°ä¸Šä¼ çš„æ–‡æ¡£ï¼ˆä½¿ç”¨æ—¶é—´æˆ³ç²¾ç¡®åŒ¹é…ï¼Œåˆ©ç”¨ç´¢å¼•ï¼‰
    const result = await pool.query(
      `SELECT text, created_at, metadata
       FROM docs
       WHERE metadata->>'uploadedAt' = $1
       ORDER BY vector <#> $2::vector ASC
       LIMIT 3`,
      [latestTimestamp, queryVector]
    );
    rows = result.rows;
    
    console.log(`ä»æ—¶é—´æˆ³ ${latestTimestamp} åŒ¹é…çš„æ–‡æ¡£ä¸­æ‰¾åˆ° ${rows.length} ä¸ªç‰‡æ®µ`);
  } else {
    // å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³ï¼Œä½¿ç”¨æ—¶é—´èŒƒå›´ï¼ˆæœ€è¿‘ 1 å°æ—¶ï¼‰
    console.log(`æ²¡æœ‰æ‰¾åˆ°æ—¶é—´æˆ³ï¼Œä½¿ç”¨æ—¶é—´èŒƒå›´æ£€ç´¢ï¼ˆæœ€è¿‘ 1 å°æ—¶ï¼‰...`);
    const result = await pool.query(
      `SELECT text, created_at, metadata
       FROM docs
       WHERE created_at >= NOW() - INTERVAL '1 hour'
       ORDER BY vector <#> $1::vector ASC
       LIMIT 3`,
      [queryVector]
    );
    rows = result.rows;
  }
  
  console.log(`æ£€ç´¢åˆ° ${rows.length} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ`);

  const context = rows.map(r => r.text).join("\n---\n");
  // Use prompt template for RAG Q&A
  const { ragQAPrompt } = await import("./prompts/rag-prompts.js");
  const prompt = ragQAPrompt.template(context, query);
  console.log(`ğŸ“ Using prompt: ${ragQAPrompt.id}`);

  // Return streaming response
  return streamText({
    model: openai("gpt-4o-mini"),
    prompt,
  });
}

// Generate document summary (non-streaming, returns complete text)
export async function summarizeDocument(): Promise<string> {
  const query = "Please summarize the main content of this document, including key points, important information, and key conclusions.";
  
  console.log(`ğŸ” æ­£åœ¨ç”ŸæˆæŸ¥è¯¢å‘é‡...`);
  const { embeddings: [queryEmbedding] } = await embedMany({
    values: [query],
    model: openai.embedding("text-embedding-3-small"),
  });

  const pool = getPool();

  // æ£€ç´¢ç­–ç•¥ï¼šåªæ£€ç´¢æœ€æ–°ä¸Šä¼ çš„æ–‡æ¡£
  // ä¼˜åŒ–ï¼šå‡å°‘æ£€ç´¢ç‰‡æ®µæ•°é‡ï¼ˆä»10ä¸ªå‡å°‘åˆ°5ä¸ªï¼‰ï¼Œæé«˜æŸ¥è¯¢é€Ÿåº¦
  const queryVector = `[${queryEmbedding.join(",")}]`;
  
  // æ‰¾å‡ºæœ€æ–°ä¸Šä¼ çš„æ–‡æ¡£æ—¶é—´æˆ³ï¼ˆä½¿ç”¨ç´¢å¼•ä¼˜åŒ–ï¼‰
  const latestDocResult = await pool.query(
    `SELECT metadata->>'uploadedAt' as latest_timestamp
     FROM docs
     WHERE metadata->>'uploadedAt' IS NOT NULL
     ORDER BY (metadata->>'uploadedAt')::bigint DESC
     LIMIT 1`
  );
  
  const latestTimestamp = latestDocResult.rows[0]?.latest_timestamp;
  
  let rows;
  
  if (latestTimestamp) {
    // åªæ£€ç´¢æœ€æ–°ä¸Šä¼ çš„æ–‡æ¡£ï¼ˆä½¿ç”¨æ—¶é—´æˆ³ç²¾ç¡®åŒ¹é…ï¼Œåˆ©ç”¨ç´¢å¼•ï¼‰
    // ä¼˜åŒ–ï¼šå‡å°‘åˆ°5ä¸ªç‰‡æ®µï¼Œè¶³å¤Ÿç”Ÿæˆæ€»ç»“
    const result = await pool.query(
      `SELECT text, created_at, metadata
       FROM docs
       WHERE metadata->>'uploadedAt' = $1
       ORDER BY vector <#> $2::vector ASC
       LIMIT 5`,
      [latestTimestamp, queryVector]
    );
    rows = result.rows;
    
    console.log(`æ€»ç»“ï¼šä»æ—¶é—´æˆ³ ${latestTimestamp} åŒ¹é…çš„æ–‡æ¡£ä¸­æ‰¾åˆ° ${rows.length} ä¸ªç‰‡æ®µ`);
  } else {
    // å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³ï¼Œä½¿ç”¨æ—¶é—´èŒƒå›´ï¼ˆæœ€è¿‘ 1 å°æ—¶ï¼‰
    console.log(`æ€»ç»“ï¼šæ²¡æœ‰æ‰¾åˆ°æ—¶é—´æˆ³ï¼Œä½¿ç”¨æ—¶é—´èŒƒå›´æ£€ç´¢ï¼ˆæœ€è¿‘ 1 å°æ—¶ï¼‰...`);
    const result = await pool.query(
      `SELECT text, created_at, metadata
       FROM docs
       WHERE created_at >= NOW() - INTERVAL '1 hour'
       ORDER BY vector <#> $1::vector ASC
       LIMIT 5`,
      [queryVector]
    );
    rows = result.rows;
  }
  
  console.log(`æ€»ç»“ï¼šæ£€ç´¢åˆ° ${rows.length} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ`);

  if (rows.length === 0) {
    return "Unable to find document content for summarization.";
  }

  const context = rows.map(r => r.text).join("\n---\n");
  // Use prompt template for document summarization
  const { documentSummaryPrompt } = await import("./prompts/rag-prompts.js");
  const prompt = documentSummaryPrompt.template(context);
  console.log(`ğŸ“ Using prompt: ${documentSummaryPrompt.id}`);

  // Non-streaming generation, get complete text
  console.log(`ğŸ¤– æ­£åœ¨ç”Ÿæˆæ€»ç»“...`);
  const stream = streamText({
    model: openai("gpt-4o-mini"),
    prompt,
  });
  
  let fullText = "";
  for await (const chunk of stream.textStream) {
    fullText += chunk;
  }

  return fullText;
}

